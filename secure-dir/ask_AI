import llm
import os
import subprocess

# --- CẤU HÌNH API KEY ---
def add_key():
    """Hỏi nhập key trước, nếu bỏ trống thì kiểm tra file cấu hình."""
    user_key = input("Nhập Gemini API key (bỏ qua nếu đã có): ").strip()

    config_path = os.path.expanduser("~/.config/llm/keys.json")

    # Nếu nhập key
    if user_key:
        try:
            process = subprocess.Popen(
                ["llm", "keys", "set", "gemini"],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            out, err = process.communicate(input=user_key + "\n")

            if process.returncode == 0:
                print("Đã thêm key cho Gemini thành công.\n")
            else:
                print(f"Lỗi khi thiết lập key: {err or out}")
        except FileNotFoundError:
            print("Chưa cài đặt thư viện 'llm'. Vui lòng chạy: pip install llm")
            exit(1)
        return 

    # Nếu không nhập key
    if os.path.exists(config_path):
        with open(config_path, encoding="utf-8") as f:
            content = f.read()
            if '"gemini"' in content:
                print("Đã phát hiện Gemini API key, bỏ qua bước thêm key.\n")
                return
            else:
                print("Không tìm thấy key cho Gemini trong cấu hình.")
    else:
        print("Không tìm thấy tệp cấu hình key.")

    # Nếu đến đây mà chưa có key → yêu cầu nhập lại
    print("\nVui lòng nhập Gemini API key để tiếp tục.")
    add_key()

def main():
    print("======== Kiểm tra log bằng Gemini AI ========")
    print("     (1) login.log")
    print("     (2) command_log.txt")
    choice = input("Chọn tệp để phân tích (1 hoặc 2): ")
    if choice == '1':
        file_to_analyze = 'login.log'
    elif choice == '2':
        file_to_analyze = 'command_log.txt'
    else:
        print("Lựa chọn không hợp lệ. Vui lòng chọn 1 hoặc 2.")
        exit(1)
    analyze_file(file_to_analyze)

def analyze_file(file_path):
    add_key()
    model = llm.get_model("gemini-2.5-flash")

    attachments = [
        llm.Attachment(path=file_path),
    ]

    # --- GỌI API ---
    try:
        response = model.prompt(
            "Phân tích tệp đính kèm và đưa ra các hoạt động đáng chú ý hoặc bất thường được ghi lại trong tệp này.",
            attachments=attachments
        )
        print("="*40)
        print(response.text())
        print("="*40)
    except Exception as e:
        print(f"Đã xảy ra lỗi: {e}")

if __name__ == "__main__":
    main()
